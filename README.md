# ğŸ”¬ Photonic-Inspired Reservoir Computing

A neuromorphic machine learning system simulating a **quantized photonic reservoir**, designed for stability analysis and image classification tasks. Includes custom experiments on convergence, divergence, classification accuracy on MNIST (with and without HOG), and Bayesian optimization using Optuna.

![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)

---

## ğŸ“ Project Structure

```
photonic-reservoir/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ reservoir/
â”‚       â”œâ”€â”€ core.py              # Core reservoir model
â”‚       â”œâ”€â”€ leaky.py             # Leaky reservoir model (alpha control)
â”‚       â”œâ”€â”€ utils.py             # Utility functions (metrics, plotting)
â”‚       â””â”€â”€ hog_features.py      # HOG preprocessing utilities
â”œâ”€â”€ experiments/                 # All experiment scripts (numbered)
â”‚   â”œâ”€â”€ 01_random_dynamics_demo.py
â”‚   â”œâ”€â”€ 02_stability_divergence_curves.py
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ report/
â”‚   â””â”€â”€ report.pdf               # Final 26-page academic report
â”œâ”€â”€ figures/                     #  Key figures and visualizations
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore
```

---

## ğŸ’¡ Overview

This project was developed as part of a neuromorphic computing course at **CentraleSupÃ©lec** (ST7). It implements a **fast, quantized simulation of a photonic-inspired reservoir** using NumPy, and explores:

- Stability & divergence using pseudo-Lyapunov curves  
- Convergence speed under leaky integration  
- MNIST classification using raw and HOG features  
- Hyperparameter optimization (Î³, Iâ‚€, Î¼) via Bayesian methods  
- End-to-end benchmarking with a ridge regression readout  

---

## âš™ï¸ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/Paul92150/photonic-reservoir.git
cd photonic-reservoir
pip install -r requirements.txt
```

---

## ğŸš€ Running Experiments

All experiments are located in the `experiments/` folder.  
To run any of them, use the following command from the root of the project:

```bash
python experiments/05_leaky_convergence_analysis.py
```

### ğŸ“‚ Highlights

| File                                | Description                                      |
|-------------------------------------|--------------------------------------------------|
| `02_stability_divergence_curves.py` | Pseudo-Lyapunov divergence over time            |
| `04_stability_heatmap.py`           | Heatmap of max divergence vs (Î³, Iâ‚€)            |
| `05_leaky_convergence_analysis.py`  | Convergence time analysis with leaky integration |
| `06_mnist_first_results.py`         | MNIST classification with raw / HOG features    |
| `07_optuna_mnist_hog.py`            | Bayesian optimization of reservoir parameters   |
| `08_hog_gamma_I0_bayopt.py`         | Joint HOG + reservoir hyperparameter search     |

---

## ğŸ“Š Results

- âœ… 98.86% test accuracy on MNIST (HOG + tuned reservoir with 8000 neurons)  
- ğŸ“‰ Leaky integration improves convergence times (Î± â‰ˆ 0.4â€“0.7 optimal)  
- ğŸ“ˆ Clear stability-chaos transitions observed in divergence plots  

â¡ï¸ See all figures and discussion in `report/report.pdf`.

---

## ğŸ”§ Key Features

- Fully quantized model (inner & outer bit-depth, clippings)
- Reservoir size customizable from 256 to 8000+
- Supports one-shot (`transform`) and temporal (`simulate_series`) dynamics
- Compatible with Optuna for full pipeline optimization
- Lightweight and fast: built with NumPy, scikit-learn, scikit-image

---

## ğŸ“„ License

This project is licensed under the MIT License.  
Feel free to use, modify, and build upon it. See [LICENSE](LICENSE).

---

## ğŸ§  Summary (Non-Technical)

This project simulates how a brain-like wave-based system processes images.  
It mimics **photonic reservoirs** (light-based neural networks) with a digital simulation.  
The goal is to explore their behavior and test their ability to recognize handwritten digits (MNIST).  
Despite its simplicity, the model reaches ~99% accuracy and exhibits fascinating properties like **memory**, **chaos**, and **stability**.

---

## ğŸ‘¤ Author

**Paul Lemaire**  
ğŸ“ CentraleSupÃ©lec Student (Gap Year â€“ AI/ML)  
ğŸ“« Contact: paul.lemaire@student-cs.fr  
ğŸŒ GitHub: [Paul92150](https://github.com/Paul92150)
